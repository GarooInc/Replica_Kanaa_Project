## Kaana Data Agent

Gu√≠a r√°pida de instalaci√≥n y ejecuci√≥n usando uv (gestor de paquetes/entornos ultrarr√°pido para Python).

### Requisitos

- Python 3.13 o superior (seg√∫n `pyproject.toml`).
- uv instalado.
	- Windows (PowerShell):
		```powershell
		winget install Astral.Uv
		# Verificar
		uv --version
		```
	- Alternativa: pipx
		```powershell
		pipx install uv
		```

### Clonar el repositorio

```powershell
git clone https://github.com/GarooInc/kaana_data_agent.git
cd kaana_data_agent
```

### Crear y activar el entorno con uv

```powershell
# Crea el entorno virtual (por defecto en .venv)
uv venv .venv

# Activa el entorno en PowerShell
.\.venv\Scripts\Activate.ps1

# (Opcional) Establecer como entorno por defecto de uv en este proyecto
uv python pin
```

Si PowerShell bloquea la ejecuci√≥n de scripts, puedes habilitarla (como administrador):

```powershell
Set-ExecutionPolicy -Scope CurrentUser -ExecutionPolicy RemoteSigned
```

### Instalar dependencias del proyecto

Este proyecto declara dependencias en `pyproject.toml`. Para instalarlas:

```powershell
# Instala/resolve dependencias seg√∫n pyproject (+ lockfile si existe)
uv sync
```

Agregar nuevas dependencias (ejemplos):

```powershell
# Dependencia de runtime
uv add requests

# Dependencia de desarrollo
uv add --dev ruff pytest
```

Actualizar dependencias (resolver de nuevo):

```powershell
uv lock --upgrade
uv sync
```

### Variables de entorno

El proyecto incluye `python-dotenv`, por lo que puedes crear un archivo `.env` en la ra√≠z para tus claves/configuraciones. Ejemplo:

```
# .env (ejemplo)
OPENAI_API_KEY=sk-...
COHERE_API_KEY=...
```

Si existe un `.env.example`, c√≥pialo:

```powershell
Copy-Item .env.example .env
```

### Ejecutar la API (FastAPI + Uvicorn)

Hay una aplicaci√≥n FastAPI en `main.py` con el objeto `app`. La forma m√°s fiable de lanzarla es invocar Uvicorn apuntando a ese objeto directamente (evita ejecutar `python main.py` si no es necesario):

```powershell
uv run uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

- Documentaci√≥n interactiva: http://localhost:8000/docs
- Esquema OpenAPI: http://localhost:8000/openapi.json

Endpoint principal disponible:

- POST `/ask` ‚Äî cuerpo JSON: `{ "question": "...", "message_history": [] }`

Prueba r√°pida desde PowerShell con Invoke-RestMethod:

```powershell
$body = @{ question = "Hola, ¬øc√≥mo est√°s?"; message_history = @() } | ConvertTo-Json
Invoke-RestMethod -Uri http://localhost:8000/ask -Method Post -Body $body -ContentType 'application/json'
```

Nota sobre streaming: el endpoint `/ask` devuelve eventos tipo Server-Sent Events (SSE) para streaming de tokens. Para probar SSE, usa un cliente compatible (por ejemplo, un frontend o `curl`/`wget` desde un entorno que no sea PowerShell) o herramientas como `Postman` con soporte de SSE.

### Comandos √∫tiles con uv

```powershell
# Ejecutar un script/comando dentro del entorno (sin activar)
uv run python -V

# Listar paquetes instalados
uv pip list

# Limpiar cach√© de uv
uv cache clean
```

### Estructura del proyecto (resumen)

```
main.py                      # Punto de entrada FastAPI (objeto app)
app/
	streaming/
		streaming.py             # L√≥gica de streaming SSE
		event_handler.py         # Utilidades para formatear eventos SSE
	utilities/
		photo_uploader.py        # Utilidad para subir im√°genes
```

### Problemas conocidos / notas

- El archivo `pyproject.toml` requiere Python >= 3.13. Aseg√∫rate de tener esa versi√≥n disponible (uv la gestionar√° si est√° instalada). Si necesitas instalar Python 3.13 en Windows:
	```powershell
	winget install Python.Python.3.13
	```
- Si prefieres ejecutar con hot-reload, usa `--reload` como en el comando de ejemplo.

### Desarrollo y pruebas (opcional)

```powershell
# A√±adir herramientas de desarrollo
uv add --dev pytest ruff

# Lanzar tests (si existen)
uv run pytest -q

# Lint (ejemplo con ruff)
uv run ruff check .
```

---

Hecho con uv y FastAPI üöÄ

## Arquitectura y m√≥dulos

### Visi√≥n general

El proyecto implementa una API de FastAPI que expone:

- `POST /ask`: genera respuestas con streaming de tokens v√≠a Server‚ÄëSent Events (SSE) usando LangChain + OpenAI.
- `PUT /contextrebuild`: reindexa contenido Markdown en un √≠ndice FAISS para Retrieval‚ÄëAugmented Generation (RAG).

Durante el ciclo de vida de la app, se inicializa un retriever global (FAISS + Cohere Embeddings) que alimenta la herramienta de contexto del hotel. El flujo de streaming sigue un esquema ReAct: el modelo puede invocar herramientas, consumir sus resultados y luego producir una respuesta final en streaming.

### Estructura por paquetes

- `main.py`
	- Crea la app FastAPI y configura `lifespan` para inicializar el retriever global.
	- Endpoint `PUT /contextrebuild`: reconstruye el √≠ndice FAISS desde archivos Markdown subidos y actualiza el retriever global.
	- Endpoint `POST /ask`: devuelve una `StreamingResponse` que emite eventos SSE desde `app/streaming/streaming.py`.

- `app/streaming/`
	- `streaming.py`: coraz√≥n del flujo SSE. Implementa `ask_streaming()` (async generator) con:
		- Construcci√≥n de historial con `SystemMessage`, historial previo y la pregunta del usuario.
		- LLM `ChatOpenAI` con `streaming=True` y herramientas vinculadas (lazy) v√≠a `bind_tools()`.
		- Bucle ReAct con m√°x. `max_iterations` (por defecto 8) para manejar tool calls:
			- Sin tool calls: hace streaming de la respuesta final (`answer`) y termina (`done`).
			- Con tool calls: ejecuta herramientas (ver `tool_execution.py`), agrega `ToolMessage` al historial, emite eventos de uso (`tool_usage`) y contin√∫a iterando.
			- Registra bit√°cora de herramientas en `tool_log` (incluida al final si hubo herramientas).
			- Maneja errores por iteraci√≥n y globales, emitiendo un `answer` gen√©rico y `done`.
		- Integraci√≥n opcional de im√°genes: intenta subir la primera imagen encontrada en el repo (ver `photo_uploader.py`) y agrega un markdown `![image](URL)` al final de la respuesta.
	- `event_handler.py`: utilidades para formatear eventos SSE.
		- `send_event(event_type, data)`: emite l√≠neas SSE `event:` y `data:` con `data` codificado como JSON y sello de tiempo.
		- `send_error(message, code)`: atajo que emite un evento `error` con `{ error, code? }`.
		- `send_done()`: evento final `done` con `{}`.
	- `lazy_loading.py`: configuraci√≥n y bind perezoso del LLM.
		- Instancia global de `ChatOpenAI` (`model="gpt-4o"`, `streaming=True`).
		- `bind_tools(tools, force_rebind=False)`: cachea la instancia enlazada a herramientas para evitar rebinds innecesarios. Registra un warning si cambia la huella de herramientas.
	- `tool_execution.py`: envoltorio para ejecutar herramientas y registrar su estado en `tool_log`.
		- Soporta `ainvoke(...)` (async) y `run(...)` (sync). Registra `started`, `completed` o `error` con detalles.

- `app/agent_tools/`
	- `rag_tool.py`: construye la herramienta `hotel_context_search` con `create_retriever_tool(...)` a partir del retriever global. Inicializaci√≥n perezosa y segura.
	- `tool_getter.py`: ensambla la lista de herramientas del agente: `hotel_context_search` (si disponible) y `strategic_web_search` (Tavily).
	- `websearch_tool.py`: integra `TavilySearch` como herramienta `strategic_web_search` y define su `args_schema` (Pydantic).

- `app/rag/`
	- `rag_indexer.py`: indexador de Markdown ‚Üí FAISS.
		- Parseo jer√°rquico de secciones (encabezados), segmentaci√≥n con `RecursiveCharacterTextSplitter`, embeddings `CohereEmbeddings` (`embed-multilingual-light-v3.0`).
		- Persiste `FAISS` y `chunk_store.json` en `app/data/hotel_context_faiss_index/`.
		- `index_markdown_contents(..., rebuild=True|False)` para reconstrucci√≥n o actualizaci√≥n incremental.
	- `rag_store.py`: gesti√≥n del √≠ndice y retriever global.
		- `load_vectorstore()`, `get_retriever(k)`, `set_global_retriever(...)`, `get_global_retriever()`.
		- `initialize_hotel_context_tool()` para inicializar expl√≠citamente la tool RAG si se requiere.

- `app/prompt/enhanced_prompt.py`
	- `get_enhanced_prompt(question, tools)` devuelve un prompt base con instrucciones de estilo de respuesta (Markdown, idioma, veracidad, etc.).
	- Hooks `check_for_tools(...)` y `check_for_fshotexamples(...)` (placeholders) para enriquecer din√°micamente el prompt.

- `app/utilities/photo_uploader.py`
	- `upload_first_photo_found()`: busca la primera imagen en el repo (excluye carpetas comunes), la sube al servidor y retorna la URL. Se usa opcionalmente en streaming para adjuntar una imagen al final.

### Streaming: eventos SSE y consumo

`/ask` retorna una respuesta con `media_type: text/event-stream`. Los eventos emitidos son:

- `answer`: contenido parcial o final del modelo. `data` es JSON con `content` y `timestamp`.
- `tool_usage`: mensajes informativos sobre el uso/estado de una herramienta.
- `tool_log`: bit√°cora al final del flujo con entradas `{ iteration, tool_name, tool_args, status, error? }`.
- `error`: error est√°ndar con `{ error, code? }`.
- `done`: marca el fin del stream. `data` es `{}`.

Formato SSE por l√≠nea:

```
event: <tipo>
data: { ...json... }

```

Ejemplo de consumo con `curl` (PowerShell no maneja bien SSE interactivo):

```bash
curl -N -X POST http://localhost:8000/ask \
	-H "Content-Type: application/json" \
	-d '{"question":"¬øQu√© amenidades ofrece el hotel?","message_history":[]}'
```

### Flujo l√≥gico de `ask_streaming()`

1. Construye historial (System + historial previo + pregunta actual).
2. Enlaza herramientas disponibles de forma perezosa (`bind_tools`).
3. Itera hasta `max_iterations`:
	 - Si no hay tool calls: hace streaming de la respuesta final (`answer`), opcionalmente agrega una imagen, emite `tool_log` si aplica y cierra con `done`.
	 - Si hay tool calls: ejecuta cada herramienta (`execute_tool`), a√±ade `ToolMessage` al historial, emite `tool_usage` y contin√∫a.
	 - Si hay error: emite `answer` gen√©rico y `done`.
4. Si se agotan iteraciones: fuerza una respuesta final en streaming y cierra.

### A√±adir nuevas herramientas

1. Implementa la herramienta compatible con LangChain (`run(...)` o `ainvoke(...)`).
2. Declara su `name` y `description` (y `args_schema` si recibe par√°metros estructurados).
3. Exp√≥rtala desde `app/agent_tools/<tu_tool>.py`.
4. Agr√©gala en `app/agent_tools/tool_getter.py` para que `get_agent_tools()` la incluya y quede disponible para el modelo.

### Variables de entorno necesarias

- `OPENAI_API_KEY`: requerido por `langchain_openai`.
- `COHERE_API_KEY`: requerido por `CohereEmbeddings` (RAG).
- `TAVILY_API_KEY`: requerido por `TavilySearch` (b√∫squeda web).

Puedes gestionarlas en `.env` (cargado autom√°ticamente por `python-dotenv`).

### Notas y buenas pr√°cticas

- Para el streaming, consume eventos SSE con clientes compatibles (navegador/FetchEventSource, `curl -N`, Postman con SSE, etc.).
- Si reindexas con `/contextrebuild`, el retriever global y la tool RAG se actualizan autom√°ticamente.
- `bind_tools` cachea el LLM enlazado a herramientas; si cambias la lista de tools en caliente, considera `force_rebind=True` (ajuste por c√≥digo si lo necesitas).

